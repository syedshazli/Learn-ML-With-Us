{"cells":[{"cell_type":"markdown","metadata":{},"source":["This file serves to be my introduction to using PyTorch. Will be referencing PyTorch docs. Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n","\n","Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see Bridge with NumPy). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autograd section). \n","\n","For now, import packages"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Initialize tensors\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n"]}],"source":["data = [[1, 2],[3, 4]]\n","data1D = [1, 5, 6, 9]\n","x_data = torch.tensor(data)\n","x1dData = torch.tensor(data)\n","print(x1dData)\n","print(x_data)"]},{"cell_type":"markdown","metadata":{},"source":["Ones tensor and random tensor example"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.8949, 0.3145],\n","        [0.4430, 0.1484]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"cell_type":"markdown","metadata":{},"source":["Attrubutes of a Tensor"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 1.],\n","        [1., 1.],\n","        [1., 1.],\n","        [1., 1.],\n","        [1., 1.]])\n","tensor([1., 1., 1., 1., 1.])\n","tensor([1., 1.])\n","tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.]])\n","Notice the number of rows stay the same but number of columns are appended for each col dimension in their tensor\n"]}],"source":["# check if tensor operations can be run on GPU. By default, created on CPU\n","if torch.cuda.is_available():\n","    tensor = tensor.to(\"cuda\")\n","\n","\n","tensor = torch.ones(5, 2)\n","\n","print(tensor)\n","\n","#first column\n","print(tensor[:,0])\n","\n","# first row\n","print(tensor[0])\n","\n","\n","t1 = torch.cat([tensor, tensor, tensor, tensor], dim =1)\n","print(t1)\n","print(\"Notice the number of rows stay the same but number of columns are appended for each col dimension in their tensor\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
